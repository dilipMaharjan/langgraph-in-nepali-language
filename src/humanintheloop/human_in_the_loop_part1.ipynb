{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02386a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Howdy back atcha. What can I help you with today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 37, 'total_tokens': 52, 'completion_time': 0.017045067, 'prompt_time': 0.002034271, 'queue_time': 0.242717812, 'total_time': 0.019079338}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'finish_reason': 'stop', 'logprobs': None}, id='run--9f64c0c8-a9e1-466f-b40e-1556cfd9f869-0', usage_metadata={'input_tokens': 37, 'output_tokens': 15, 'total_tokens': 52})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROOQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0)\n",
    "\n",
    "result=llm.invoke(\"Howdy\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a504f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: float, b: float):\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    return a + b\n",
    "def subtract(a: float, b: float):\n",
    "    \"\"\"Subtracts two numbers.\"\"\"\n",
    "    return a - b\n",
    "def multiply(a: float, b: float):\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    return a * b\n",
    "def divide(a: float, b: float):\n",
    "    \"\"\"Divides two numbers.\"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84075f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m graph = builder.compile(interrupt_before=[\u001b[33m\"\u001b[39m\u001b[33mperform_task\u001b[39m\u001b[33m\"\u001b[39m], checkpointer=memory)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Show\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m display(Image(\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langgraph-in-nepali-language/langraph/lib/python3.13/site-packages/langchain_core/runnables/graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langgraph-in-nepali-language/langraph/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:293\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    287\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    288\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    289\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    290\u001b[39m         )\n\u001b[32m    291\u001b[39m     )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    301\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langgraph-in-nepali-language/langraph/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:450\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    446\u001b[39m     msg = (\n\u001b[32m    447\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    448\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    454\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#Bind tools\n",
    "tools=[add,subtract,multiply,divide]\n",
    "llm_tool=llm.bind_tools(tools)\n",
    "\n",
    "# System message prompt\n",
    "system_message = SystemMessage(content=\"You are a helpful assistant. You help do a simple arithmetic.\")\n",
    "\n",
    "# ---- Node Function ----\n",
    "def perform_task(state: MessagesState):\n",
    "    return {\"messages\":[llm_tool.invoke([system_message] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "\n",
    "# ---- Build the Graph ----\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Nodes \n",
    "builder.add_node(\"perform_task\", perform_task)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Edges\n",
    "builder.add_edge(START, \"perform_task\")\n",
    "builder.add_conditional_edges(\n",
    "    \"perform_task\", \n",
    "    tools_condition,\n",
    "    )\n",
    "builder.add_edge(\"tools\", \"perform_task\")\n",
    "\n",
    "\n",
    "# Memory saver\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile with interrupt_before if needed\n",
    "graph = builder.compile(interrupt_before=[\"perform_task\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38238b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 6.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# ---- thread config ----\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4())  # generates a new, unique thread ID\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Initial task\n",
    "task = {\"messages\": HumanMessage(content=\"Add 5 and 6.\")}\n",
    "\n",
    "# Streaming response\n",
    "for event in graph.stream(task, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a048e0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Add 5 and 6.', additional_kwargs={}, response_metadata={}, id='679e3e71-04a5-4f48-b53e-68e796315199')]}, next=('perform_task',), config={'configurable': {'thread_id': '7586901b-e761-4fc0-9a67-451a8008b6b6', 'checkpoint_ns': '', 'checkpoint_id': '1f0a1286-6010-6528-8000-9c2e192bf12e'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-10-04T13:45:33.059195+00:00', parent_config={'configurable': {'thread_id': '7586901b-e761-4fc0-9a67-451a8008b6b6', 'checkpoint_ns': '', 'checkpoint_id': '1f0a1286-600e-63c2-bfff-4d532adec402'}}, tasks=(PregelTask(id='f4067a4d-6bcb-5bc2-ea87-8d1c002b025f', name='perform_task', path=('__pregel_pull', 'perform_task'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=graph.get_state(config)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f98fdfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('perform_task',)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6335eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 6.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (bbceev1ms)\n",
      " Call ID: bbceev1ms\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "11.0\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11850b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "11.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 5 and 6 is 11.\n"
     ]
    }
   ],
   "source": [
    "# Continue to end \n",
    "for event in graph.stream(None, config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "539ec7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 7.\n"
     ]
    }
   ],
   "source": [
    "#update/edit message\n",
    "task = {\"messages\": HumanMessage(content=\"Add 5 and 7.\")}\n",
    "for event in graph.stream(task, config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4caff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '7586901b-e761-4fc0-9a67-451a8008b6b6',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a128c-4906-6548-8006-986cc08ef62c'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config,{\"messages\": [HumanMessage(content=\"No, please Add 3 and 5.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3065ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, please Add 3 and 5.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (mn4da6b4y)\n",
      " Call ID: mn4da6b4y\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35263e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 6.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (bbceev1ms)\n",
      " Call ID: bbceev1ms\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "11.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 5 and 6 is 11.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, please Add 3 and 5.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (mn4da6b4y)\n",
      " Call ID: mn4da6b4y\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "new_state=graph.get_state(config).values\n",
    "for message in new_state['messages']:\n",
    "    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
