{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1588ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Howdy back at ya! What's brewin'?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 37, 'total_tokens': 49, 'completion_time': 0.01635713, 'prompt_time': 0.002331444, 'queue_time': 0.216946143, 'total_time': 0.018688574}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_90c2e79dab', 'finish_reason': 'stop', 'logprobs': None}, id='run--ddeb5f23-5443-4de6-a324-6f4fa01e0f68-0', usage_metadata={'input_tokens': 37, 'output_tokens': 12, 'total_tokens': 49})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROOQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model_name=\"llama-3.1-8b-instant\",temperature=1.9)\n",
    "\n",
    "result=llm.invoke(\"Howdy\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db1d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class State(TypedDict):\n",
    "    joke : str\n",
    "    topic: str\n",
    "    feedback: str\n",
    "    funny_or_not:str\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"funny\", \"not funny\"]= Field(description=\"Decide if the joke is funny or not.\")\n",
    "    feedback: str= Field(description=\"If the joke is not funny,\")\n",
    "evaluator=llm.with_structured_output(Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42527be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_llm(state:State):\n",
    "    \"\"\" LLM generates a joke\"\"\"    \n",
    "    if(state.get(\"feedback\")):\n",
    "        generator=llm.invoke(\n",
    "            f\"Write a joke about {state['topic']} but take into account the feedback {state['feedback']}\"\n",
    "            )\n",
    "    else:\n",
    "        generator=llm.invoke(\n",
    "            f\"Write a joke about {state['topic']}\"\n",
    "            )\n",
    "    print(generator.content)\n",
    "    return {\"joke\": generator.content}\n",
    "\n",
    "def evaluator_llm(state:State):\n",
    "    \"\"\" LLM evaluates a joke\"\"\"    \n",
    "    grade=evaluator.invoke(\n",
    "        f\"Grade the joke {state['joke']}\"\n",
    "    )\n",
    "    print(grade)\n",
    "    return {\"funny_or_not\":grade.grade, \"feedback\":grade.feedback}\n",
    "\n",
    "def route_joke(state:State):\n",
    "    \"\"\" Routes back to the generator or end from evaluator\"\"\"  \n",
    "   \n",
    "    if(state[\"funny_or_not\"]==\"funny\"):\n",
    "        print(\"Accepted\")\n",
    "        return \"Accepted\"\n",
    "    if(state[\"funny_or_not\"]==\"not funny\"):\n",
    "        print(\"Rejected\")\n",
    "        return \"Rejected + Feedback\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe4258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Image\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "graph= StateGraph(State)\n",
    "\n",
    "#Add nodes\n",
    "graph.add_node(\"generator_llm\",generator_llm)\n",
    "graph.add_node(\"evaluator_llm\",evaluator_llm)\n",
    "\n",
    "#Add edges\n",
    "graph.add_edge(START,\"generator_llm\")\n",
    "graph.add_edge(\"generator_llm\",\"evaluator_llm\")\n",
    "graph.add_conditional_edges(\n",
    "    \"evaluator_llm\",\n",
    "    route_joke,\n",
    "    {\n",
    "        \"Accepted\":END,\n",
    "        \"Rejected + Feedback\":\"generator_llm\"\n",
    "    }\n",
    ")\n",
    "\n",
    "#Compile graph\n",
    "graph=graph.compile()\n",
    "\n",
    "# graph_image=graph.get_graph().draw_mermaid_png()\n",
    "# display(Image(graph_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5d6caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the cat join a band? Because it wanted to be a purr-cussionist.\n",
      "grade='not funny' feedback='The cat in band as purr-cussionis was quite corny but did manage to pull a very faint grin from this side; perhaps some will like it. '\n",
      "Rejected\n",
      "Why did the musician always bring a ladder to the gig? He wanted to take his solos to new heights. \"New heights\" sounds similar to what one says of musical talent being 'at new hights, however this was written 'at it and not as that'\n",
      "grade='not funny' feedback=\"The joke sounds like wordplay related more to common sayings 'heights' but not much to do with the 'gig' so this makes the punch line confusing.\"\n",
      "Rejected\n",
      "A musician goes to a new high-security venue - they charge high fees so now I need my Gig with Heights.\n",
      "\n",
      "However, here is the joke in two simple lines, to improve the connection:\n",
      "\n",
      "A musician goes to gig at the Eiffel Tower \n",
      "I guess I needed that heights.\n",
      "grade='not funny' feedback=\"You need more connection between this line 'Eiffel TOWER' and the  heights as this is more of a name with height not literal 'HEIGHTS in the title'. A better version maybe: a musician to a concert with an amazing high HEIGHT view. So the line  - 'Gig with Heights.', doesn't flow that well \"\n",
      "Rejected\n",
      "Here's a revised single-line joke to incorporate your concept:\n",
      "\n",
      "I asked my music friends to meet me at the Eiffel Tower during a concert night with epic Gig with HEIGHT - the perfect place for a High-Note Experience.\n",
      "\n",
      "This rewritten joke maintains a theme centered around HEIGHT while also connecting \"Gig with Heights\" better with Eiffel Tower height which makes more sense for it not being a height title, rather an event venue\n",
      "grade='funny' feedback=\"The revised single-line joke has effectively linked 'HIGH NOTES EXPERIENCE'. You maintained a central theme centered around HEIGHT that connects it to the Eiffel Tower perfectly\"\n",
      "Accepted\n",
      "Here's a revised single-line joke to incorporate your concept:\n",
      "\n",
      "I asked my music friends to meet me at the Eiffel Tower during a concert night with epic Gig with HEIGHT - the perfect place for a High-Note Experience.\n",
      "\n",
      "This rewritten joke maintains a theme centered around HEIGHT while also connecting \"Gig with Heights\" better with Eiffel Tower height which makes more sense for it not being a height title, rather an event venue\n"
     ]
    }
   ],
   "source": [
    "state=graph.invoke({\"topic\":\"Write a single line joke\"})\n",
    "print(state['joke'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
